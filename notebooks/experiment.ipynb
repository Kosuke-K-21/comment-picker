{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d350e732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "import asyncio\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, BinaryContent, ModelRetry\n",
    "from pydantic_ai.messages import ModelRequest, ModelResponse\n",
    "from pydantic_ai.models.bedrock import BedrockConverseModel, BedrockModelSettings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv_path = os.path.join('..', '.env')\n",
    "dotenv.load_dotenv(dotenv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae376e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agent(\n",
    "    model_id: str,\n",
    "    output_type: Optional[BaseModel | str] = str,\n",
    "    retries: int = 5,\n",
    "    temperature: float = 0.2,\n",
    "    max_tokens: int = 20000,\n",
    "    timeout: int = 60,\n",
    ") -> Agent:\n",
    "\n",
    "    model = BedrockConverseModel(model_name=model_id)\n",
    "\n",
    "    model_settings = BedrockModelSettings(\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    agent = Agent(\n",
    "        model,\n",
    "        retries=retries,\n",
    "        output_type=output_type,\n",
    "        model_settings=model_settings,\n",
    "        system_prompt = \"\"\"\n",
    "        あなたは講義に関するフィードバックを分析するAIアシスタントです。\n",
    "        以下のルールに従って、コメントを分類してください。\n",
    "        1. コメントの感情を分類してください。\n",
    "        2. コメントのカテゴリを分類してください。\n",
    "        3. コメントの重要度を分類してください。\n",
    "        4. コメントの共通性を分類してください。\n",
    "        \n",
    "        x`各分類は以下の選択肢から選んでください。\n",
    "        \n",
    "        感情: ポジティブ, 中立, ネガティブ\n",
    "        カテゴリ: 講義内容, 講義資料, 運営, その他\n",
    "        重要度: 高, 中, 低\n",
    "        共通性: 高, 中, 低\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    return agent\n",
    "\n",
    "\n",
    "async def generate_content_with_agent(\n",
    "    model_id: str,\n",
    "    query: list[str | BinaryContent],\n",
    "    history: list[ModelRequest | ModelResponse] = [],\n",
    "    output_type: Optional[BaseModel | str] = str,\n",
    "    retries: int = 3,\n",
    "    temperature: float = 0.2,\n",
    "    max_tokens: int = 20000,\n",
    "    timeout: int = 60,\n",
    ") -> tuple[str, int, int, int]:\n",
    "\n",
    "    await asyncio.sleep(0.5)  # APIレート制限対策\n",
    "\n",
    "    agent = generate_agent(\n",
    "        model_id,\n",
    "        output_type,\n",
    "        retries=retries,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    response = await agent.run(\n",
    "        query,\n",
    "        message_history=history,\n",
    "    )\n",
    "    output = response.output\n",
    "\n",
    "    input_tokens = response.usage().request_tokens\n",
    "    output_tokens = response.usage().response_tokens\n",
    "    total_tokens = response.usage().total_tokens\n",
    "    think_tokens = total_tokens - input_tokens - output_tokens\n",
    "\n",
    "\n",
    "    return output, input_tokens, output_tokens, think_tokens\n",
    "\n",
    "def calculate_cost(\n",
    "    model_name: str,\n",
    "    input_tokens: int,\n",
    "    output_tokens: int,\n",
    "    think_tokens: Optional[int] = None,\n",
    ") -> tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculate the total cost based on input, output, and think tokens.\n",
    "    \"\"\"\n",
    "    if think_tokens is None:\n",
    "        think_tokens = 0\n",
    "\n",
    "    if \"gemini-2.0-flash\" in model_name:\n",
    "        input_cost_per_mil_token = 0.15\n",
    "        output_cost_per_mil_token = 0.60\n",
    "\n",
    "    elif \"gemini-2.5-flash\" in model_name:\n",
    "        input_cost_per_mil_token = 0.15\n",
    "        if think_tokens == 0:\n",
    "            output_cost_per_mil_token = 0.60\n",
    "        else:\n",
    "            output_cost_per_mil_token = 3.5\n",
    "    \n",
    "    elif \"amazon.nova-lite-v1:0\" in model_name:\n",
    "        input_cost_per_mil_token = 0.00006 * 1000  # Convert to per million tokens\n",
    "        output_cost_per_mil_token = 0.00024 * 1000  # Convert to per million tokens\n",
    "    \n",
    "    elif \"amazon.nova-pro-v1:0\" in model_name:\n",
    "        input_cost_per_mil_token = 0.0008 * 1000\n",
    "        output_cost_per_mil_token = 0.0032 * 1000\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    input_cost = input_tokens * input_cost_per_mil_token * 1e-6\n",
    "    output_cost = output_tokens * output_cost_per_mil_token * 1e-6\n",
    "    think_cost = think_tokens * output_cost_per_mil_token * 1e-6\n",
    "\n",
    "    return input_cost, output_cost, think_cost\n",
    "\n",
    "\n",
    "class SentimentEnum(str, Enum):\n",
    "    POSITIVE = 'ポジティブ'\n",
    "    NEUTRAL = '中立'\n",
    "    NEGATIVE = 'ネガティブ'\n",
    "\n",
    "class CategoryEnum(str, Enum):\n",
    "    LECTURE_CONTENT = '講義内容'\n",
    "    LECTURE_MATERIAL = '講義資料'\n",
    "    OPERATION = '運営'\n",
    "    OTHER = 'その他'\n",
    "\n",
    "class ImportanceEnum(str, Enum):\n",
    "    HIGH = '高'\n",
    "    MEDIUM = '中'\n",
    "    LOW = '低'\n",
    "\n",
    "class CommonalityEnum(str, Enum):\n",
    "    HIGH = '高'\n",
    "    MEDIUM = '中'\n",
    "    LOW = '低'\n",
    "\n",
    "\n",
    "class EvalOutput(BaseModel):\n",
    "    sentiment: SentimentEnum = Field(description=\"コメントに対する感情の分類\")\n",
    "    category: CategoryEnum = Field(description=\"コメントに対するカテゴリの分類\")\n",
    "    importance: ImportanceEnum = Field(description=\"コメントに対する重要度の分類\")\n",
    "    commonality: CommonalityEnum = Field(description=\"コメントに対する共通性の分類\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30caca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Day1 with model amazon.nova-lite-v1:0...\n"
     ]
    }
   ],
   "source": [
    "data_days = [\"Day1\", \"Day2\", \"Day3\"]\n",
    "models = [\"amazon.nova-lite-v1:0\", \"amazon.nova-pro-v1:0\"]\n",
    "data_dir = os.path.join(\"..\", \"data\")\n",
    "\n",
    "for day in data_days:\n",
    "    for model in models:\n",
    "        print(f\"Processing {day} with model {model}...\")\n",
    "        comment_df = pd.read_excel(os.path.join(data_dir, f\"{day}_アンケート.xlsx\"))\n",
    "        \n",
    "        total_score_column = \"本日の総合的な満足度を５段階で教えてください。 \"\n",
    "        recommend_score_column = \"親しいご友人にこの講義の受講をお薦めしますか？\"\n",
    "        comments_column = [col for col in comment_df.columns if \"必須\" in col or \"任意\" in col]\n",
    "        # pandasからコメントを抽出して、辞書型の文字列のリストに変換\n",
    "        total_scores = comment_df[total_score_column].tolist()\n",
    "        recommend_scores = comment_df[recommend_score_column].tolist()\n",
    "        comments = comment_df[comments_column].apply(\n",
    "            lambda row: json.dumps(row.dropna().to_dict(), ensure_ascii=False), axis=1\n",
    "        ).tolist()\n",
    "\n",
    "        tasks = [\n",
    "            generate_content_with_agent(\n",
    "                model_id=model,\n",
    "                query=[comment],\n",
    "                output_type=EvalOutput,\n",
    "                retries=3,\n",
    "                temperature=0.2,\n",
    "                max_tokens=2000,\n",
    "                timeout=60,\n",
    "            )\n",
    "            for comment in comments\n",
    "        ]\n",
    "\n",
    "        semaphore = asyncio.Semaphore(50)\n",
    "        async with semaphore:\n",
    "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "        # Process results\n",
    "        processed_results = []\n",
    "        for result in results:\n",
    "            if isinstance(result, Exception):\n",
    "                print(f\"Error: {result}\")\n",
    "                result_dict = {\n",
    "                    \"sentiment\": None,\n",
    "                    \"category\": None,\n",
    "                    \"importance\": None,\n",
    "                    \"commonality\": None,\n",
    "                    \"total_cost\": 0,\n",
    "                    \"is_error\": True,\n",
    "                }\n",
    "            else:\n",
    "                output, input_tokens, output_tokens, think_tokens = result\n",
    "\n",
    "                input_cost, output_cost, think_cost = calculate_cost(\n",
    "                    model_name=model,\n",
    "                    input_tokens=input_tokens,\n",
    "                    output_tokens=output_tokens,\n",
    "                    think_tokens=think_tokens,\n",
    "                )\n",
    "                total_cost = input_cost + output_cost + think_cost\n",
    "\n",
    "                result_dict = output.model_dump()\n",
    "                for k, v in result_dict.items():\n",
    "                        result_dict[k] = v.value\n",
    "                result_dict.update({\n",
    "                    \"total_cost\": total_cost,\n",
    "                    \"is_error\": False,\n",
    "                })\n",
    "\n",
    "            processed_results.append(result_dict)\n",
    "\n",
    "        # evaluation\n",
    "        results_df = pd.DataFrame(processed_results)\n",
    "\n",
    "        # is_errorのTrueを数えて、results_dfから削除\n",
    "        error_count = results_df['is_error'].sum()\n",
    "        print(f\"Error Rate: {error_count / len(results_df):.2%}\")\n",
    "        comment_df = comment_df[~results_df['is_error']]\n",
    "        results_df = results_df[~results_df['is_error']]\n",
    "\n",
    "        # 感情のaccuracyを計算\n",
    "        sentiment_pred = results_df['sentiment'].map({\n",
    "            SentimentEnum.POSITIVE: 1,\n",
    "            SentimentEnum.NEUTRAL: 0,\n",
    "            SentimentEnum.NEGATIVE: -1\n",
    "        })\n",
    "\n",
    "        sentiment_act = comment_df[total_score_column].map({\n",
    "            5: 1,\n",
    "            4: 1,\n",
    "            3: 0,\n",
    "            2: -1,\n",
    "            1: -1,\n",
    "        })\n",
    "        sentiment_accuracy = (sentiment_pred == sentiment_act).mean()\n",
    "        print(f\"Sentiment Accuracy: {sentiment_accuracy:.2%}\")\n",
    "\n",
    "        # 感情、重要度、共通性の掛け算からスコアを算出、点数との相関を計算\n",
    "        importance_map = {\n",
    "            ImportanceEnum.HIGH: 3,\n",
    "            ImportanceEnum.MEDIUM: 2,\n",
    "            ImportanceEnum.LOW: 1\n",
    "        }\n",
    "        commonality_map = {\n",
    "            CommonalityEnum.HIGH: 3,\n",
    "            CommonalityEnum.MEDIUM: 2,\n",
    "            CommonalityEnum.LOW: 1\n",
    "        }\n",
    "        results_df['score'] = sentiment_pred * results_df['importance'].map(importance_map) * results_df['commonality'].map(commonality_map)\n",
    "        # 1-5にスケールを合わせる\n",
    "        results_df['score'] = (results_df['score'] + 9) / 18 * 4 + 1\n",
    "\n",
    "        comment_df[\"点数\"] = comment_df[total_score_column] * 0.5 + comment_df[recommend_score_column] * 0.5 / 2\n",
    "\n",
    "        score_corr = results_df['score'].corr(comment_df['点数'])\n",
    "        print(f\"Score Correlation: {score_corr:.2f}\")\n",
    "\n",
    "        # コストを表示\n",
    "        total_cost = results_df['total_cost'].sum()\n",
    "        print(f\"Total Cost: ${total_cost:.4f}\")\n",
    "\n",
    "        print(\"-\" * 20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
