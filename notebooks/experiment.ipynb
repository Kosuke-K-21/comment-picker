{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d350e732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "import asyncio\n",
    "import warnings\n",
    "\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, BinaryContent, ModelRetry\n",
    "from pydantic_ai.messages import ModelRequest, ModelResponse\n",
    "from pydantic_ai.models.gemini import GeminiModel, GeminiModelSettings\n",
    "from pydantic_ai.providers.google_vertex import GoogleVertexProvider\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv_path = os.path.join('..', '.env')\n",
    "dotenv.load_dotenv(dotenv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae376e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agent(\n",
    "    model_id: str,\n",
    "    output_type: Optional[BaseModel | str] = str,\n",
    "    retries: int = 5,\n",
    "    temperature: float = 0.2,\n",
    "    max_tokens: int = 20000,\n",
    "    timeout: int = 60,\n",
    ") -> Agent:\n",
    "\n",
    "    model = GeminiModel(\n",
    "        model_id, provider=GoogleVertexProvider(region=os.getenv(\"GCP_LOCATION\"))\n",
    "    )\n",
    "\n",
    "    model_settings = GeminiModelSettings(\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    agent = Agent(\n",
    "        model,\n",
    "        retries=retries,\n",
    "        output_type=output_type,\n",
    "        model_settings=model_settings,\n",
    "    )\n",
    "\n",
    "    return agent\n",
    "\n",
    "\n",
    "async def generate_content_with_agent(\n",
    "    model_id: str,\n",
    "    query: list[str | BinaryContent],\n",
    "    history: list[ModelRequest | ModelResponse] = [],\n",
    "    output_type: Optional[BaseModel | str] = str,\n",
    "    retries: int = 3,\n",
    "    temperature: float = 0.2,\n",
    "    max_tokens: int = 20000,\n",
    "    timeout: int = 60,\n",
    ") -> tuple[str, int, int, int]:\n",
    "\n",
    "    await asyncio.sleep(0.5)  # APIレート制限対策\n",
    "\n",
    "    agent = generate_agent(\n",
    "        model_id,\n",
    "        output_type,\n",
    "        retries=retries,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "\n",
    "    response = await agent.run(\n",
    "        query,\n",
    "        message_history=history,\n",
    "    )\n",
    "    output = response.output\n",
    "\n",
    "    input_tokens = response.usage().request_tokens\n",
    "    output_tokens = response.usage().response_tokens\n",
    "    total_tokens = response.usage().total_tokens\n",
    "    think_tokens = total_tokens - input_tokens - output_tokens\n",
    "\n",
    "\n",
    "    return output, input_tokens, output_tokens, think_tokens\n",
    "\n",
    "def calculate_cost(\n",
    "    model_name: str,\n",
    "    input_tokens: int,\n",
    "    output_tokens: int,\n",
    "    think_tokens: Optional[int] = None,\n",
    ") -> tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculate the total cost based on input, output, and think tokens.\n",
    "    \"\"\"\n",
    "    if think_tokens is None:\n",
    "        think_tokens = 0\n",
    "\n",
    "    if \"gemini-2.0-flash\" in model_name:\n",
    "        input_cost_per_mil_token = 0.15\n",
    "        output_cost_per_mil_token = 0.60\n",
    "\n",
    "    elif \"gemini-2.5-flash\" in model_name:\n",
    "        input_cost_per_mil_token = 0.15\n",
    "        if think_tokens == 0:\n",
    "            output_cost_per_mil_token = 0.60\n",
    "        else:\n",
    "            output_cost_per_mil_token = 3.5\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")\n",
    "\n",
    "    input_cost = input_tokens * input_cost_per_mil_token * 1e-6\n",
    "    output_cost = output_tokens * output_cost_per_mil_token * 1e-6\n",
    "    think_cost = think_tokens * output_cost_per_mil_token * 1e-6\n",
    "\n",
    "    return input_cost, output_cost, think_cost\n",
    "\n",
    "\n",
    "class SentimentEnum(str, Enum):\n",
    "    POSITIVE = 'ポジティブ'\n",
    "    NEUTRAL = '中立'\n",
    "    NEGATIVE = 'ネガティブ'\n",
    "\n",
    "class CategoryEnum(str, Enum):\n",
    "    LECTURE_CONTENT = '講義内容'\n",
    "    LECTURE_MATERIAL = '講義資料'\n",
    "    OPERATION = '運営'\n",
    "    OTHER = 'その他'\n",
    "\n",
    "class ImportanceEnum(str, Enum):\n",
    "    HIGH = '高'\n",
    "    MEDIUM = '中'\n",
    "    LOW = '低'\n",
    "\n",
    "class CommonalityEnum(str, Enum):\n",
    "    HIGH = '高'\n",
    "    MEDIUM = '中'\n",
    "    LOW = '低'\n",
    "\n",
    "\n",
    "class EvalOutput(BaseModel):\n",
    "    sentiment: SentimentEnum = Field(description=\"コメントに対する感情の分類\")\n",
    "    category: CategoryEnum = Field(description=\"コメントに対するカテゴリの分類\")\n",
    "    importance: ImportanceEnum = Field(description=\"コメントに対する重要度の分類\")\n",
    "    commonality: CommonalityEnum = Field(description=\"コメントに対する共通性の分類\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c30caca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing day1 with model gemini-2.0-flash...\n",
      "Error Rate: 0.00%\n",
      "Sentiment Accuracy: 81.47%\n",
      "Category Accuracy: 59.91%\n",
      "Category Accuracy by Group:\n",
      "category\n",
      "その他     0.387755\n",
      "講義内容    0.559701\n",
      "講義資料    0.933333\n",
      "運営      0.894737\n",
      "dtype: float64\n",
      "Score Correlation: 0.80\n",
      "Total Cost: $0.0045\n",
      "--------------------\n",
      "Processing day1 with model gemini-2.5-flash-preview-05-20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/w1g0jlhn2qn21yvz6vftvj8h0000gp/T/ipykernel_98209/343474464.py:92: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  category_accuracy_by_group = results_df.groupby('category').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 0.00%\n",
      "Sentiment Accuracy: 85.34%\n",
      "Category Accuracy: 62.07%\n",
      "Category Accuracy by Group:\n",
      "category\n",
      "その他     0.000000\n",
      "講義内容    0.562500\n",
      "講義資料    0.928571\n",
      "運営      0.760000\n",
      "dtype: float64\n",
      "Score Correlation: 0.79\n",
      "Total Cost: $0.2738\n",
      "--------------------\n",
      "Processing day2 with model gemini-2.0-flash...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/w1g0jlhn2qn21yvz6vftvj8h0000gp/T/ipykernel_98209/343474464.py:92: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  category_accuracy_by_group = results_df.groupby('category').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 0.00%\n",
      "Sentiment Accuracy: 79.82%\n",
      "Category Accuracy: 62.16%\n",
      "Category Accuracy by Group:\n",
      "category\n",
      "その他     0.386792\n",
      "講義内容    0.650273\n",
      "講義資料    0.907692\n",
      "運営      0.634146\n",
      "dtype: float64\n",
      "Score Correlation: 0.81\n",
      "Total Cost: $0.0083\n",
      "--------------------\n",
      "Processing day2 with model gemini-2.5-flash-preview-05-20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/w1g0jlhn2qn21yvz6vftvj8h0000gp/T/ipykernel_98209/343474464.py:92: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  category_accuracy_by_group = results_df.groupby('category').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 0.00%\n",
      "Sentiment Accuracy: 81.65%\n",
      "Category Accuracy: 62.16%\n",
      "Category Accuracy by Group:\n",
      "category\n",
      "その他     0.259259\n",
      "講義内容    0.595506\n",
      "講義資料    0.855072\n",
      "運営      0.630137\n",
      "dtype: float64\n",
      "Score Correlation: 0.79\n",
      "Total Cost: $0.4792\n",
      "--------------------\n",
      "Processing day3 with model gemini-2.0-flash...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/w1g0jlhn2qn21yvz6vftvj8h0000gp/T/ipykernel_98209/343474464.py:92: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  category_accuracy_by_group = results_df.groupby('category').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 0.00%\n",
      "Sentiment Accuracy: 82.62%\n",
      "Category Accuracy: 64.38%\n",
      "Category Accuracy by Group:\n",
      "category\n",
      "その他     0.295455\n",
      "講義内容    0.655319\n",
      "講義資料    0.952381\n",
      "運営      0.750000\n",
      "dtype: float64\n",
      "Score Correlation: 0.86\n",
      "Total Cost: $0.0091\n",
      "--------------------\n",
      "Processing day3 with model gemini-2.5-flash-preview-05-20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/w1g0jlhn2qn21yvz6vftvj8h0000gp/T/ipykernel_98209/343474464.py:92: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  category_accuracy_by_group = results_df.groupby('category').apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Rate: 0.00%\n",
      "Sentiment Accuracy: 83.05%\n",
      "Category Accuracy: 70.82%\n",
      "Category Accuracy by Group:\n",
      "category\n",
      "その他     0.125000\n",
      "講義内容    0.668852\n",
      "講義資料    0.938462\n",
      "運営      0.787500\n",
      "dtype: float64\n",
      "Score Correlation: 0.81\n",
      "Total Cost: $0.5423\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bm/w1g0jlhn2qn21yvz6vftvj8h0000gp/T/ipykernel_98209/343474464.py:92: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  category_accuracy_by_group = results_df.groupby('category').apply(\n"
     ]
    }
   ],
   "source": [
    "data_days = [\"day1\", \"day2\", \"day3\"]\n",
    "models = [\"gemini-2.0-flash\", \"gemini-2.5-flash-preview-05-20\"]\n",
    "data_dir = os.path.join(\"..\", \"data\")\n",
    "\n",
    "for day in data_days:\n",
    "    for model in models:\n",
    "        print(f\"Processing {day} with model {model}...\")\n",
    "        act_df = pd.read_csv(os.path.join(data_dir, f\"{day}_アンケート.csv\"))\n",
    "        comments = act_df['コメント'].tolist()\n",
    "\n",
    "        tasks = [\n",
    "            generate_content_with_agent(\n",
    "                model_id=model,\n",
    "                query=[comment],\n",
    "                output_type=EvalOutput,\n",
    "                retries=3,\n",
    "                temperature=0.2,\n",
    "                max_tokens=2000,\n",
    "                timeout=60,\n",
    "            )\n",
    "            for comment in comments\n",
    "        ]\n",
    "\n",
    "        semaphore = asyncio.Semaphore(50)\n",
    "        async with semaphore:\n",
    "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "        # Process results\n",
    "        processed_results = []\n",
    "        for result in results:\n",
    "            if isinstance(result, Exception):\n",
    "                print(f\"Error: {result}\")\n",
    "                result_dict = {\n",
    "                    \"sentiment\": None,\n",
    "                    \"category\": None,\n",
    "                    \"importance\": None,\n",
    "                    \"commonality\": None,\n",
    "                    \"total_cost\": 0,\n",
    "                    \"is_error\": True,\n",
    "                }\n",
    "            else:\n",
    "                output, input_tokens, output_tokens, think_tokens = result\n",
    "\n",
    "                input_cost, output_cost, think_cost = calculate_cost(\n",
    "                    model_name=model,\n",
    "                    input_tokens=input_tokens,\n",
    "                    output_tokens=output_tokens,\n",
    "                    think_tokens=think_tokens,\n",
    "                )\n",
    "                total_cost = input_cost + output_cost + think_cost\n",
    "\n",
    "                result_dict = output.model_dump()\n",
    "                for k, v in result_dict.items():\n",
    "                        result_dict[k] = v.value\n",
    "                result_dict.update({\n",
    "                    \"total_cost\": total_cost,\n",
    "                    \"is_error\": False,\n",
    "                })\n",
    "\n",
    "            processed_results.append(result_dict)\n",
    "\n",
    "        # evaluation\n",
    "        results_df = pd.DataFrame(processed_results)\n",
    "\n",
    "        # is_errorのTrueを数えて、results_dfから削除\n",
    "        error_count = results_df['is_error'].sum()\n",
    "        print(f\"Error Rate: {error_count / len(results_df):.2%}\")\n",
    "        act_df = act_df[~results_df['is_error']]\n",
    "        results_df = results_df[~results_df['is_error']]\n",
    "\n",
    "        # 感情のaccuracyを計算\n",
    "        sentiment_pred = results_df['sentiment'].map({\n",
    "            SentimentEnum.POSITIVE: 1,\n",
    "            SentimentEnum.NEUTRAL: 0,\n",
    "            SentimentEnum.NEGATIVE: -1\n",
    "        })\n",
    "\n",
    "        sentiment_act = act_df[\"点数\"].map({\n",
    "            5: 1,\n",
    "            4: 1,\n",
    "            3: 0,\n",
    "            2: -1,\n",
    "            1: -1,\n",
    "        })\n",
    "        sentiment_accuracy = (sentiment_pred == sentiment_act).mean()\n",
    "        print(f\"Sentiment Accuracy: {sentiment_accuracy:.2%}\")\n",
    "\n",
    "        # カテゴリのaccuracyを計算\n",
    "        category_accuracy = (results_df['category'] == act_df['カテゴリ']).mean()\n",
    "        print(f\"Category Accuracy: {category_accuracy:.2%}\")\n",
    "        # カテゴリごとのaccuracyを表示\n",
    "        category_accuracy_by_group = results_df.groupby('category').apply(\n",
    "            lambda x: (x['category'] == act_df.loc[x.index, 'カテゴリ']).mean()\n",
    "        )\n",
    "        print(\"Category Accuracy by Group:\")\n",
    "        print(category_accuracy_by_group)\n",
    "\n",
    "        # 感情、重要度、共通性の掛け算からスコアを算出、点数との相関を計算\n",
    "        importance_map = {\n",
    "            ImportanceEnum.HIGH: 3,\n",
    "            ImportanceEnum.MEDIUM: 2,\n",
    "            ImportanceEnum.LOW: 1\n",
    "        }\n",
    "        commonality_map = {\n",
    "            CommonalityEnum.HIGH: 3,\n",
    "            CommonalityEnum.MEDIUM: 2,\n",
    "            CommonalityEnum.LOW: 1\n",
    "        }\n",
    "        results_df['score'] = sentiment_pred * results_df['importance'].map(importance_map) * results_df['commonality'].map(commonality_map)\n",
    "        # 1-5にスケールを合わせる\n",
    "        results_df['score'] = (results_df['score'] + 9) / 18 * 4 + 1\n",
    "\n",
    "        score_corr = results_df['score'].corr(act_df['点数'])\n",
    "        print(f\"Score Correlation: {score_corr:.2f}\")\n",
    "\n",
    "        # コストを表示\n",
    "        total_cost = results_df['total_cost'].sum()\n",
    "        print(f\"Total Cost: ${total_cost:.4f}\")\n",
    "\n",
    "        print(\"-\" * 20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
